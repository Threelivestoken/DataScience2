{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 --- imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364aa45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 --- make dataframe\n",
    "df = pd.read_csv(\"cyberbullying.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8674e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 --- make column with words\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame name\n",
    "\n",
    "df['words'] = df['tweet_text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193d9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 --- makes column with individual characters\n",
    "df['characters'] = df['tweet_text'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76243ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 --- Most common letter\n",
    "\n",
    "def get_top_characters(text):\n",
    "    # Removing spaces from the text\n",
    "    text = text.replace(\" \", \"\")\n",
    "    \n",
    "    # Counting the occurrences of each character\n",
    "    char_counts = {}\n",
    "    for char in text:\n",
    "        char_counts[char] = char_counts.get(char, 0) + 1\n",
    "    \n",
    "    # Sorting the characters by count in descending order\n",
    "    sorted_chars = sorted(char_counts, key=char_counts.get, reverse=True)\n",
    "\n",
    "    # Getting the 5 most common characters\n",
    "    top_characters = sorted_chars[:5]\n",
    "\n",
    "    # If there are less than 5 unique characters, padding with spaces\n",
    "    top_characters += [' '] * (5 - len(top_characters))\n",
    "\n",
    "    return top_characters\n",
    "\n",
    "# Applying the function to each row of the 'tweet_text' column\n",
    "df['top_letters'] = df['tweet_text'].apply(lambda x: get_top_letters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ee55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for taco in range(len(df['top_letters'])):\n",
    "    print(df['top_letters'][taco][0],\n",
    "          df['top_letters'][taco][1],\n",
    "          df['top_letters'][taco][2],\n",
    "          df['top_letters'][taco][3],\n",
    "          df['top_letters'][taco][4],df['cyberbullying_type'][taco])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb188a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_cyberbullying', 'gender', 'religion', 'other_cyberbullying',\n",
       "       'age', 'ethnicity'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cyberbullying_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a4316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637a22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted cyberbullying type for the test instance is: not_cyberbullying\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum([1 for x, y in zip(point1, point2) if x != y]))\n",
    "\n",
    "# Function to implement K-nearest neighbor algorithm\n",
    "def k_nearest_neighbors(training_data, test_instance, k):\n",
    "    distances = []\n",
    "\n",
    "    for index, row in training_data.iterrows():\n",
    "        features = np.array(row['top_letters'])\n",
    "        target = row['cyberbullying_type']\n",
    "        dist = euclidean_distance(test_instance, features)\n",
    "        distances.append((dist, target))\n",
    "\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "\n",
    "    neighbors = distances[:k]\n",
    "\n",
    "    # Count the occurrences of each class in the k-nearest neighbors\n",
    "    class_votes = {}\n",
    "    for neighbor in neighbors:\n",
    "        class_label = neighbor[1]\n",
    "        class_votes[class_label] = class_votes.get(class_label, 0) + 1\n",
    "\n",
    "    # Return the class with the most votes\n",
    "    return max(class_votes, key=class_votes.get)\n",
    "\n",
    "# Convert letters to numerical features (binary representation)\n",
    "unique_characters = set(char for sublist in df['top_letters'] for char in sublist)\n",
    "character_mapping = {char: i for i, char in enumerate(unique_characters)}\n",
    "\n",
    "for char in unique_characters:\n",
    "    df[char] = df['top_letters'].apply(lambda x: 1 if char in x else 0)\n",
    "\n",
    "# Sample test instance\n",
    "test_instance = [1 if char in ['a', 'b', 'c', 'd', 'e'] else 0 for char in unique_characters]\n",
    "\n",
    "# Example usage of k_nearest_neighbors\n",
    "k_value = 100\n",
    "result = k_nearest_neighbors(df, test_instance, k_value)\n",
    "\n",
    "print(f'The predicted cyberbullying type for the test instance is: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    # Remove emojis\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    print(\"Starting preprocessing...\")\n",
    "\n",
    "\n",
    "    # Clean the text data\n",
    "    print(\"Cleaning text data...\")\n",
    "    df[\"tweet_text\"] = df[\"tweet_text\"].apply(clean_text)\n",
    "    print(\"Text data cleaned.\")\n",
    "\n",
    "\n",
    "    # Create a CountVectorizer instance\n",
    "    print(\"Creating CountVectorizer instance...\")\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=5000\n",
    "    )  # Adjust the number of features as needed\n",
    "    print(\"CountVectorizer instance created.\")\n",
    "\n",
    "\n",
    "    # Apply the vectorizer to the tweet texts to transform them into a Bag of Words model\n",
    "    print(\"Applying CountVectorizer to tweet texts...\")\n",
    "    X = vectorizer.fit_transform(df[\"tweet_text\"])\n",
    "    print(\"CountVectorizer applied.\")\n",
    "\n",
    "\n",
    "    # Use 'cyberbullying_type' as the target variable\n",
    "    print(\"Setting target variable...\")\n",
    "    y = df[\"cyberbullying_type\"]\n",
    "    print(\"Target variable set.\")\n",
    "\n",
    "\n",
    "    # Convert X to an array if it's not already\n",
    "    print(\"Converting feature matrix to array...\")\n",
    "    X_array = X.toarray()\n",
    "    print(\"Feature matrix converted to array.\")\n",
    "\n",
    "\n",
    "    # Split the data into training and testing sets (70% train, 30% test)\n",
    "    print(\"Splitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_array, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    print(\"Data split into training and testing sets.\")\n",
    "\n",
    "\n",
    "    # Reset the indexes and convert the Series to NumPy arrays for y_train and y_test\n",
    "    print(\"Resetting indexes and converting to NumPy arrays...\")\n",
    "    y_train = y_train.reset_index(drop=True).to_numpy()\n",
    "    y_test = y_test.reset_index(drop=True).to_numpy()\n",
    "    print(\"Indexes reset and conversion to NumPy arrays completed.\")\n",
    "\n",
    "\n",
    "    print(\"Preprocessing completed.\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call preprocess and get the train/test splits\n",
    "X_train, X_test, y_train, y_test = preprocess(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# KNN algorithm\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        print(f\"Initializing KNN with k={k}\")\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"Fitting model...\")\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        print(\"Model fitted.\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Making predictions...\")\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        print(\"Predictions made.\")\n",
    "        return np.array(y_pred)\n",
    "\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute distances\n",
    "        print(\"Computing distances...\")\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        print(\"Distances computed.\")\n",
    "\n",
    "\n",
    "        # Sort and get k nearest neighbors\n",
    "        print(\"Finding k nearest neighbors...\")\n",
    "        k_indices = np.argsort(distances)[: self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        print(\"k nearest neighbors found.\")\n",
    "\n",
    "\n",
    "        # Most common label\n",
    "        print(\"Determining the most common label...\")\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        print(\"Most common label determined.\")\n",
    "        return most_common[0][0]\n",
    "        # Function to find the best k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_best_k(X_train, X_test, y_train, y_test, min_k=1, max_k=20, step=2):\n",
    "    best_k = min_k\n",
    "    best_accuracy = 0\n",
    "\n",
    "\n",
    "    print(\"Searching for the best k...\")\n",
    "\n",
    "\n",
    "    for k in range(min_k, max_k + 1, step):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        predictions = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(f\"k = {k}: Accuracy = {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment below lines to use the custom KNN algorithm\n",
    "# knn_custom = KNN(k=3)\n",
    "# knn_custom.fit(X_train, y_train)\n",
    "# predictions_custom = knn_custom.predict(X_test)\n",
    "# accuracy_custom = np.sum(predictions_custom == y_test) / len(y_test)\n",
    "# print(f\"Custom KNN Accuracy: {accuracy_custom}\")\n",
    "\n",
    "\n",
    "# Find the best k value\n",
    "best_k = find_best_k(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "# Using scikit-learn's KNeighborsClassifier with the best k\n",
    "print(f\"Using scikit-learn's KNeighborsClassifier with k = {best_k}...\")\n",
    "knn_sklearn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_sklearn.fit(X_train, y_train)\n",
    "predictions_sklearn = knn_sklearn.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_sklearn = np.mean(predictions_sklearn == y_test)\n",
    "print(f\"scikit-learn KNN with k = {best_k} Accuracy: {accuracy_sklearn}\")\n",
    "\n",
    "\n",
    "# Using scikit-learn's KNeighborsClassifier\n",
    "print(\"Using scikit-learn's KNeighborsClassifier...\")\n",
    "knn_sklearn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_sklearn.fit(X_train, y_train)\n",
    "predictions_sklearn = knn_sklearn.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_sklearn = np.mean(predictions_sklearn == y_test)\n",
    "print(f\"scikit-learn KNN Accuracy: {accuracy_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436576e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a45484",
   "metadata": {},
   "outputs": [],
   "source": [
    "activ(18.71499999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3ddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee690610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ea7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquewords=df['characters'].explode().unique()\n",
    "uniquewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uniquewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for taco in range(len(df['words'])):\n",
    "    for burrito in range(len(df['words'][taco])):\n",
    "        x=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_df = pd.DataFrame({'word': df['words'].explode().unique()})\n",
    "unique_words_df['word_number'] = range(1, len(unique_words_df) + 1)\n",
    "\n",
    "# Merge the original DataFrame with the unique word DataFrame\n",
    "df = df.merge(unique_words_df, left_on='words', right_on='word', how='left')\n",
    "\n",
    "# Drop unnecessary columns and reset index\n",
    "df = df.drop(['word', 'words'], axis=1).sort_values(by=['tweet_text']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c13ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fv(b,h,v):\n",
    "    mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1110bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function\n",
    "def activ(a):\n",
    "    e=2.718281828459045235360287471352\n",
    "    if a>18.715:\n",
    "        1\n",
    "    elif a<-18.715:\n",
    "        -1\n",
    "    else:\n",
    "        activ_temp_1=(e**(a)-e**(-a))/(e**(a)+e**(-a))\n",
    "    return activ_temp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input(\"what? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed97cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=input(\"Gimme a number: \")\n",
    "\n",
    "for taco in range(100):\n",
    "    x=x*x-x\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf3400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
