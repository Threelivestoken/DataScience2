{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364aa45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "df = pd.read_csv(\"cyberbullying.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8674e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame name\n",
    "\n",
    "df['words'] = df['tweet_text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193d9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "df['characters'] = df['tweet_text'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee690610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>words</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[In, other, words, #katandandre,, your, food, ...</td>\n",
       "      <td>[I, n,  , o, t, h, e, r,  , w, o, r, d, s,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[Why, is, #aussietv, so, white?, #MKR, #theblo...</td>\n",
       "      <td>[W, h, y,  , i, s,  , #, a, u, s, s, i, e, t, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[@XochitlSuckkks, a, classy, whore?, Or, more,...</td>\n",
       "      <td>[@, X, o, c, h, i, t, l, S, u, c, k, k, k, s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[@Jason_Gio, meh., :P, thanks, for, the, heads...</td>\n",
       "      <td>[@, J, a, s, o, n, _, G, i, o,  , m, e, h, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[@RudhoeEnglish, This, is, an, ISIS, account, ...</td>\n",
       "      <td>[@, R, u, d, h, o, e, E, n, g, l, i, s, h,  , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "                                               words  \\\n",
       "0  [In, other, words, #katandandre,, your, food, ...   \n",
       "1  [Why, is, #aussietv, so, white?, #MKR, #theblo...   \n",
       "2  [@XochitlSuckkks, a, classy, whore?, Or, more,...   \n",
       "3  [@Jason_Gio, meh., :P, thanks, for, the, heads...   \n",
       "4  [@RudhoeEnglish, This, is, an, ISIS, account, ...   \n",
       "\n",
       "                                          characters  \n",
       "0  [I, n,  , o, t, h, e, r,  , w, o, r, d, s,  , ...  \n",
       "1  [W, h, y,  , i, s,  , #, a, u, s, s, i, e, t, ...  \n",
       "2  [@, X, o, c, h, i, t, l, S, u, c, k, k, k, s, ...  \n",
       "3  [@, J, a, s, o, n, _, G, i, o,  , m, e, h, ., ...  \n",
       "4  [@, R, u, d, h, o, e, E, n, g, l, i, s, h,  , ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551ea7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'n', ' ', 'o', 't', 'h', 'e', 'r', 'w', 'd', 's', '#', 'k',\n",
       "       'a', ',', 'y', 'u', 'f', 'c', 'p', 'i', 'l', '!', 'm', 'W', 'v',\n",
       "       '?', 'M', 'K', 'R', 'b', 'A', 'C', 'U', '1', '0', 'N', 'g', 'T',\n",
       "       '@', 'X', 'S', 'O', 'J', '_', 'G', '.', ':', 'P', 'E', 'L', 'j',\n",
       "       '5', 'Q', 'Y', 'x', 'B', 'D', '/', '2', '4', 'Ç', 'ğ', 'ü', 'ç',\n",
       "       '…', '-', '\"', 'F', 'Z', '=', '(', 'H', 'V', \"'\", '3', 'z', '8',\n",
       "       '9', '😘', '❤', 'م', 'د', 'ي', 'ن', 'ة', 'ح', 'ب', 'ز', 'ا', '&',\n",
       "       ';', '|', 'é', '7', ']', 'q', ')', 'ó', '😌', '›', 'ã', '6', 'É',\n",
       "       'Ã', '+', '\\\\', '~', '–', '🍋', '$', '😭', 'ê', '♥', '%', '*', '^',\n",
       "       '️', 'á', 'í', '👏', 'º', '😁', '🙏', '¬', '͡', '˛', '”', '’', '😂',\n",
       "       '¿', 'ş', 'ı', '[', 'ð', '\\x9f', '\\x98', '\\x82', '¤', '·', '\\x8f',\n",
       "       '½', 'â', '\\x80', '\\x8d', '\\x99', 'ï', '¸', 'ʃ', '˘', '̩', 'ƪ',\n",
       "       '\\u200e', '\\u200b', 'ñ', '😏', '😝', '“', '😒', '😄', '⌣', '́', '̀',\n",
       "       '☹', '\\x97', '©', '🎁', 'ú', 'õ', '\\xa0', '☺', '🙅', '😍', '👌', '🎶',\n",
       "       '\\x88', '\\x91', '»', '\\x92', 'ª', '😷', '😱', '😰', '😅', '😜', '😀',\n",
       "       '😩', '😨', '👍', '\\x84', '\\xad', '¦', '👎', '😉', '\\r', '\\n', '💩', '💔',\n",
       "       '🏀', '💅', '💁', 'ā', '😃', '😔', '😢', '😐', '😊', 'ˆ', '✌', '🙈', '🙀',\n",
       "       '💉', '‘', '😲', '🔫', '😦', '😡', 'Ў', 'ΰ', '\\x85', '😋', 'ë', 'Щ', 'Д',\n",
       "       'щ', '🐚', '😴', 'İ', 'ö', '•', '😓', '¾', '™', 'Ê', '\\ue022', '👳',\n",
       "       'à', '®', '²', '¥', '\\x87', '¹', '\\x81', '\\x9c', '🍴', '👠', '👗',\n",
       "       '❌', '—', '🐧', '🎧', '🎵', '💦', '😆', '😈', 'Ô', '💙', '👯', '😟', '😠',\n",
       "       '💐', 'Ó', '😤', '\\x9a', '\\x9b', '✨', 'な', 'ぁ', 'パ', 'ン', 'ツ', 'ち',\n",
       "       'ょ', 'ー', 'だ', 'い', '。', 'く', 'れ', 'よ', '！', 'ォ', 'お', '前', 'ら',\n",
       "       'え', 'や', 'か', 'っ', '\\u3000', '（', '・', '）', 'ô', '👉', '📷', '😧',\n",
       "       '📱', '😵', 'è', '💋', '💬', '👔', '👿', 'ì', '🍩', '♪', '☑', 'ˇ', '∫',\n",
       "       '¡', '\\uf04a', '🕡', '🕟', '🕠', '🕞', '🕥', '🕗', '🕛', 'î', '🙌', 'ل',\n",
       "       'ر', 'ص', 'ف', '🍗', '\\x83', '✘', '📖', '😚', '\\ue40e', '☝', '😣', '💜',\n",
       "       '🍓', '🍌', 'Á', '♣', '\\x9e', '\\x94', '😕', '👹', '😯', '►', '😞', '`',\n",
       "       '¨', '³', '‾', '▿', '\\x8c', 'Ú', '😬', 'ټ', '😥', '\\x9d', '¼',\n",
       "       '\\x8b', '\\x90', 'µ', '°', '╥', '﹏', 'ラ', 'ス', 'ト', 'の', '発', '見',\n",
       "       'じ', 'り', 'ワ', 'オ', 'ｗ', '\\x8e', '\\x8a', '\\x93', '\\x89', '🚬', '😳',\n",
       "       '«', '\\x95', '´', '\\x96', '§', '👢', '💕', 'з', 'ƒ', 'σ', 'È', '😛',\n",
       "       '{', '}', '【', '自', '動', '】', 'め', 'と', '殺', 'で', '、', 'も', 'す',\n",
       "       'る', 'は', '憎', '相', '手', 'を', 'し', 'た', '後', '死', 'ば', 'ろ', 'て',\n",
       "       'こ', '🙉', '💨', '🚦', '📝', '🚶', '♨', '🙊', 'Â', '£', '✋', '🐸', '☕',\n",
       "       '\\u2066', '\\u2069', '÷', '♫', '>', '👧', '👦', '¢', '¯', '『', '』',\n",
       "       '\\x86', 'ㅡ', '≠', '¶', '±', 'ค', 'ร', 'ิ', 'ส', 'พ', 'ี', 'ว', 'ั',\n",
       "       'أ', 'ش', 'ق', 'ع', 'ى', 'و', 'ه', 'น', 'ก', 'แ', 'ด', 'ง', 'ต',\n",
       "       'ึ', 'เ', 'จ', '็', 'ม', 'ป', 'ไ', 'า', 'ะ', '🍊', '🌋', '😻', 'ү',\n",
       "       '🔥', '👋', '互', 'フ', 'ロ', 'μ', '\\U000fe32d', '💪', '🐀', '🐕', '„',\n",
       "       'آ', 'پ', 'ک', 'ی', 'چ', 'ہ', 'ے', '۔', '،', 'ث', 'č', 'Ş', 'ت',\n",
       "       'श', 'ा', 'ह', 'ी', 'न', 'ब', 'ग', 'क', 'ि', 'ऊ', 'औ', 'र', 'त',\n",
       "       'े', '।', 'Μ', 'ο', '५', '़', 'ज', 'य', '्', 'म', 'س', 'ī', 'झ',\n",
       "       'ं', 'ड', 'द', 'Ä', 'अ', 'उ', 'प', 'ो', 'स', 'आ', 'ै', '▶', '𝕀',\n",
       "       '𝕨', '𝕠', '𝕦', '𝕝', '𝕕', '𝕢', '𝕖', '𝕤', '𝕥', '𝕚', '𝕟', '𝕙', '𝕒',\n",
       "       '𝕞', '𝕣', '𝕔', '€', 'Α', 'γ', 'ί', 'α', 'Σ', 'φ', '，', 'ट', 'ु',\n",
       "       'ल', 'व', '●', 'ए', '🔵', '☻', 'Ə', '🔖', '‚', 'я', '☭', '🐎', '⚠',\n",
       "       '💓', '🐟', '💃', '🍦', '🐙', '😇', '🌸', '🌟', 'н', 'о', 'й', 'р', 'е',\n",
       "       'п', 'а', 'б', 'л', 'и', 'к', '\\ue337', '\\ue40d', '\\ue402', 'ø',\n",
       "       '\\ue00d', '\\ue409', '🎼', '\\ue411', '😎', '🐊', '👊', '🏼', '🚗', '猫',\n",
       "       '足', '踏', 'み', 'レ', '✊', '😫', '🍳', '📺', '⚡', '🎥', 'ハ', 'イ', 'ニ',\n",
       "       'ュ', 'ナ', 'ウ', 'ル', 'リ', 'ア', '⠀', '─', '❞', 'Ñ', 'ᵖ', 'ᵒ', 'ⁱ',\n",
       "       'ⁿ', 'ᵗ', 'ʰ', 'ᵉ', 'ᶠ', 'ᵍ', 'ʳ', 'ᵘ', 'ˡ', 'ʷ', 'ᵐ', 'ʸ', 'ᵃ',\n",
       "       'ᵇ', 'ˢ', 'ᵛ', '▼', 'อ', 'ใ', '―', '中', '川', '大', '志', '石', '井',\n",
       "       '杏', '奈', '少', '年', '的', '你', '✎', '★', '☆', '♡', '︎', 'ä', '➤',\n",
       "       '마', '무', '솔', '라', '⨾', 'ē', 'Ū', 'Î', 'Ü', 'Ł', 'Í', 'Ę', 'Š',\n",
       "       '𝓘', '𝓷', '𝓪', '𝔀', '𝓸', '𝓻', '𝓵', '𝓭', '𝓱', '𝓮', '𝔂', '𝓾', '𝓬',\n",
       "       '𝓫', '𝓽', '𝓲', '𝓰', '𝓴', '̶', '\\u2063', '＞', '＿', '＜', 'ﾉ', '｀',\n",
       "       '˚', '𝚎', '𝚕', '𝚞', '𝚜', '𝚒', '𝚟', '概', '要', '〝', '？', '〞', 'ホ',\n",
       "       'ム', '山', '田', '裕', '貴', '𝕧', '𝕘', '𝕫', '𝕪', '𝐀', '𝐒', '𝐢', '𝐥',\n",
       "       '𝐞', '𝐧', '𝐭', '𝐕', '𝗼', '𝐜', '𝐚', '𝐮', '𝐬', '◄', '❝', '𝓂', '𝒶',\n",
       "       '𝓉', '𝒽', '𝑒', '𝓌', '𝟧', '𝟪', '\\ue412', '\\ue408', '\\ue41e',\n",
       "       '\\U000feb7b', 'Ś', 'ĺ', 'å', 'Ğ', 'Ҩ', 'ŋ', 'ԃ', '∂', '․',\n",
       "       '\\ue416', '\\ue11a', '✗', '̅', '̲', '̥', '̊', '인', '종', '차', '별',\n",
       "       '̯', '》', '‽', 'Ʊ', 'ɪ', 'ɡ', 'ə', 'ʊ', '\\ue410', '\\ue011', '◂',\n",
       "       '➳', 'ɣ', '⛽', '🅰', '🆖', '💯', '😹'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniquewords=df['characters'].explode().unique()\n",
    "uniquewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484e061c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniquewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309a7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for taco in range(len(df['words'])):\n",
    "    for burrito in range(len(df['words'][taco])):\n",
    "        x=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d163bc2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17104\\2756879296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Merge the original DataFrame with the unique word DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Drop unnecessary columns and reset index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9352\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9354\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   9355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9356\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     )\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    965\u001b[0m             )\n\u001b[0;32m    966\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;34m\"\"\"return the join indexers\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         return get_join_indexers(\n\u001b[0m\u001b[0;32m    942\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     )\n\u001b[1;32m-> 1488\u001b[1;33m     \u001b[0mzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1489\u001b[0m     \u001b[0mllab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzipped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[1;31m# get left & right join labels and num. of levels at each location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m     mapped = (\n\u001b[1;32m-> 1485\u001b[1;33m         \u001b[0m_factorize_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_factorize_keys\u001b[1;34m(lk, rk, sort, how)\u001b[0m\n\u001b[0;32m   2185\u001b[0m     \u001b[1;31m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2186\u001b[0m     \u001b[1;31m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2187\u001b[1;33m     \u001b[0mllab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2188\u001b[0m     \u001b[1;31m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2189\u001b[0m     \u001b[1;31m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas._libs.hashtable.ObjectFactorizer.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_labels\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "unique_words_df = pd.DataFrame({'word': df['words'].explode().unique()})\n",
    "unique_words_df['word_number'] = range(1, len(unique_words_df) + 1)\n",
    "\n",
    "# Merge the original DataFrame with the unique word DataFrame\n",
    "df = df.merge(unique_words_df, left_on='words', right_on='word', how='left')\n",
    "\n",
    "# Drop unnecessary columns and reset index\n",
    "df = df.drop(['word', 'words'], axis=1).sort_values(by=['tweet_text']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c13ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
